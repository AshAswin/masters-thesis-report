@Article{2015PLoSO..1030140B,
  Title                    = {On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation},
  Author                   = {{Bach}, Sebastian and {Binder}, Alexander and {Montavon}, Gr{\'e}goire and {Klauschen}, Frederick and {M{\"u}ller}, Klaus-Robert and {Samek}, Wojciech},
  Journal                  = {PLoS ONE},
  Year                     = {2015},

  Month                    = jul,
  Number                   = {7},
  Pages                    = {e0130140},
  Volume                   = {10},

  Adsnote                  = {Provided by the SAO/NASA Astrophysics Data System},
  Adsurl                   = {https://ui.adsabs.harvard.edu/abs/2015PLoSO..1030140B},
  Doi                      = {10.1371/journal.pone.0130140}
}

@Article{binder2021morphological,
  Title                    = {Morphological and molecular breast cancer profiling through explainable machine learning},
  Author                   = {Binder, Alexander and Bockmayr, Michael and H{\"a}gele, Miriam and Wienert, Stephan and Heim, Daniel and Hellweg, Katharina and Ishii, Masaru and Stenzinger, Albrecht and Hocke, Andreas and Denkert, Carsten and others},
  Journal                  = {Nature Machine Intelligence},
  Year                     = {2021},
  Number                   = {4},
  Pages                    = {355--366},
  Volume                   = {3},

  Publisher                = {Nature Publishing Group}
}

@Article{castelvecchi2016can,
  Title                    = {Can we open the black box of AI?},
  Author                   = {Castelvecchi, Davide},
  Journal                  = {Nature News},
  Year                     = {2016},
  Number                   = {7623},
  Pages                    = {20},
  Volume                   = {538}
}


@Article{hicks2021explaining,
  Title                    = {Explaining deep neural networks for knowledge discovery in electrocardiogram analysis},
  Author                   = {Hicks, Steven A and Isaksen, Jonas L and Thambawita, Vajira and Ghouse, Jonas and Ahlberg, Gustav and Linneberg, Allan and Grarup, Niels and Str{\"u}mke, Inga and Ellervik, Christina and Olesen, Morten Salling and others},
  Journal                  = {Scientific reports},
  Year                     = {2021},
  Number                   = {1},
  Pages                    = {1--11},
  Volume                   = {11},

  Publisher                = {Nature Publishing Group}
}

@InProceedings{Jetley2018,
  author    = {Saumya {Jetley} and Nicholas A. {Lord} and Namhoon {Lee} and Philip H. S. {Torr}},
  booktitle = {International Conference on Learning Representations},
  title     = {Learn To Pay Attention},
  year      = {2018},
  groups    = {ash:6},
  notes     = {Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2962961439},
  owner     = {ash},
  timestamp = {2021.12.30},
}

@Article{lee2019explainable,
  Title                    = {An explainable deep-learning algorithm for the detection of acute intracranial haemorrhage from small datasets},
  Author                   = {Lee, Hyunkwang and Yune, Sehyo and Mansouri, Mohammad and Kim, Myeongchan and Tajmir, Shahein H and Guerrier, Claude E and Ebert, Sarah A and Pomerantz, Stuart R and Romero, Javier M and Kamalian, Shahmir and others},
  Journal                  = {Nature biomedical engineering},
  Year                     = {2019},
  Number                   = {3},
  Pages                    = {173--182},
  Volume                   = {3},

  Publisher                = {Nature Publishing Group}
}

@Article{linardatos2021explainable,
  Title                    = {Explainable ai: A review of machine learning interpretability methods},
  Author                   = {Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris},
  Journal                  = {Entropy},
  Year                     = {2021},
  Number                   = {1},
  Pages                    = {18},
  Volume                   = {23},

  Publisher                = {Multidisciplinary Digital Publishing Institute}
}

@Book{molnar2019,
  Title                    = {Interpretable Machine Learning},
  Author                   = {Christoph Molnar},
  Year                     = {2019},

  Subtitle                 = {A Guide for Making Black Box Models Explainable}
}

@InProceedings{nunnari2021overlap,
  Title                    = {On the overlap between grad-cam saliency maps and explainable visual features in skin cancer images},
  Author                   = {Nunnari, Fabrizio and Kadir, Md Abdul and Sonntag, Daniel},
  Booktitle                = {International Cross-Domain Conference for Machine Learning and Knowledge Extraction},
  Year                     = {2021},
  Organization             = {Springer},
  Pages                    = {241--253}
}

@Article{qian2021prospective,
  Title                    = {Prospective assessment of breast cancer risk from multimodal multiview ultrasound images via clinically applicable deep learning},
  Author                   = {Qian, Xuejun and Pei, Jing and Zheng, Hui and Xie, Xinxin and Yan, Lin and Zhang, Hao and Han, Chunguang and Gao, Xiang and Zhang, Hanqi and Zheng, Weiwei and others},
  Journal                  = {Nature biomedical engineering},
  Year                     = {2021},
  Number                   = {6},
  Pages                    = {522--532},
  Volume                   = {5},

  Publisher                = {Nature Publishing Group}
}

@InProceedings{Santoro2017,
  author    = {Adam {Santoro} and David {Raposo} and David G. T. {Barrett} and Mateusz {Malinowski} and Razvan {Pascanu} and Peter W. {Battaglia} and Timothy P. {Lillicrap}},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {A simple neural network module for relational reasoning},
  year      = {2017},
  pages     = {4967--4976},
  volume    = {30},
  groups    = {ash:6},
  notes     = {Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2963907629},
  owner     = {ash},
  timestamp = {2021.12.30},
}

@InProceedings{tonekaboni2019clinicians,
  Title                    = {What clinicians want: contextualizing explainable machine learning for clinical end use},
  Author                   = {Tonekaboni, Sana and Joshi, Shalmali and McCradden, Melissa D and Goldenberg, Anna},
  Booktitle                = {Machine learning for healthcare conference},
  Year                     = {2019},
  Organization             = {PMLR},
  Pages                    = {359--380}
}

@InProceedings{Wang2018,
  author    = {Xiaolong {Wang} and Ross {Girshick} and Abhinav {Gupta} and Kaiming {He}},
  booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  title     = {Non-local Neural Networks},
  year      = {2018},
  pages     = {7794--7803},
  groups    = {ash:6},
  notes     = {Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2963091558},
  owner     = {ash},
  timestamp = {2021.12.30},
}

@InProceedings{xue2012window,
  Title                    = {Window classification of brain CT images in biomedical articles},
  Author                   = {Xue, Zhiyun and Antani, Sameer and Long, L Rodney and Demner-Fushman, Dina and Thoma, George R},
  Booktitle                = {AMIA Annual Symposium Proceedings},
  Year                     = {2012},
  Organization             = {American Medical Informatics Association},
  Pages                    = {1023},
  Volume                   = {2012}
}

@Article{li2017convolutional,
  author  = {Li, Christy and Konomis, Dimitris and Neubig, Graham and Xie, Pengtao and Cheng, Carol and Xing, Eric},
  journal = {arXiv preprint arXiv:1712.02768},
  title   = {Convolutional neural networks for medical diagnosis from admission notes},
  year    = {2017},
}

@Article{Schwendicke2019,
  author   = {Falk Schwendicke and Tatiana Golla and Martin Dreher and Joachim Krois},
  journal  = {Journal of Dentistry},
  title    = {Convolutional neural networks for dental image diagnostics: A scoping review},
  year     = {2019},
  issn     = {0300-5712},
  pages    = {103226},
  volume   = {91},
  abstract = {Objectives
Convolutional neural networks (CNNs) are increasingly applied for medical image diagnostics. We performed a scoping review, exploring (1) use cases, (2) methodologies and (3) findings of studies applying CNN on dental image material.
Sources
Medline via PubMed, IEEE Xplore, arXiv were searched.
Study selection
Full-text articles and conference-proceedings reporting CNN application on dental imagery were included.
Data
Thirty-six studies, published 2015-2019, were included, mainly from four countries (South Korea, United States, Japan, China). Studies focussed on general dentistry (n = 15 studies), cariology (n = 5), endodontics (n = 2), periodontology (n = 3), orthodontics (n = 3), dental radiology (2), forensic dentistry (n = 2) and general medicine (n = 4). Most often, the detection, segmentation or classification of anatomical structures, including teeth (n = 9), jaw bone (n = 2) and skeletal landmarks (n = 4) was performed. Detection of pathologies focused on caries (n = 3). The most commonly used image type were panoramic radiographs (n = 11), followed by periapical radiographs (n = 8), Cone-Beam CT or conventional CT (n = 6). Dataset sizes varied between 10–5,166 images (mean 1,053). Most studies used medical professionals to label the images and constitute the reference test. A large range of outcome metrics was employed, hampering comparisons across studies. A comparison of the CNN performance against an independent test group of dentists was provided by seven studies; most studies found the CNN to perform similar to dentists. Applicability or impact on treatment decision was not assessed at all.
Conclusions
CNNs are increasingly employed for dental image diagnostics in research settings. Their usefulness, safety and generalizability should be demonstrated using more rigorous, replicable and comparable methodology.
Clinical significance
CNNs may be used in diagnostic-assistance systems, thereby assisting dentists in a more comprehensive, systematic and faster evaluation and documentation of dental images. CNNs may become applicable in routine care; however, prior to that, the dental community should appraise them against the rules of evidence-based practice.},
  doi      = {https://doi.org/10.1016/j.jdent.2019.103226},
  keywords = {Artificial Intelligence, CNNs, Dentistry, Diagnostics, Evidence-based Dentistry, Images},
  url      = {https://www.sciencedirect.com/science/article/pii/S0300571219302283},
}

@Article{anwar2018medical,
  author    = {Anwar, Syed Muhammad and Majid, Muhammad and Qayyum, Adnan and Awais, Muhammad and Alnowami, Majdi and Khan, Muhammad Khurram},
  journal   = {Journal of medical systems},
  title     = {Medical image analysis using convolutional neural networks: a review},
  year      = {2018},
  number    = {11},
  pages     = {1--13},
  volume    = {42},
  publisher = {Springer},
}

@Article{AITSKOURT2018109,
  author   = {Brahim {Ait Skourt} and Abdelhamid {El Hassani} and Aicha Majda},
  journal  = {Procedia Computer Science},
  title    = {Lung CT Image Segmentation Using Deep Neural Networks},
  year     = {2018},
  issn     = {1877-0509},
  note     = {PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES, ICDS2017},
  pages    = {109-113},
  volume   = {127},
  abstract = {Lung CT image segmentation is a necessary initial step for lung image analysis, it is a prerequisite step to provide an accurate lung CT image analysis such as lung cancer detection. In this work, we propose a lung CT image segmentation using the U-net architecture, one of the most used architectures in deep learning for image segmentation. The architecture consists of a contracting path to extract high-level information and a symmetric expanding path that recovers the information needed. This network can be trained end-to-end from very few images and outperforms many methods. Experimental results show an accurate segmentation with 0.9502 Dice-Coefficient index.},
  doi      = {https://doi.org/10.1016/j.procs.2018.01.104},
  keywords = {Lung CT, Image Segmentation, Deep Learning, U-net},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877050918301157},
}

@Article{ozturk2020automated,
  author    = {Ozturk, Tulin and Talo, Muhammed and Yildirim, Eylul Azra and Baloglu, Ulas Baran and Yildirim, Ozal and Acharya, U Rajendra},
  journal   = {Computers in biology and medicine},
  title     = {Automated detection of COVID-19 cases using deep neural networks with X-ray images},
  year      = {2020},
  pages     = {103792},
  volume    = {121},
  publisher = {Elsevier},
}

@Article{pereira2016brain,
  author    = {Pereira, S{\'e}rgio and Pinto, Adriano and Alves, Victor and Silva, Carlos A},
  journal   = {IEEE transactions on medical imaging},
  title     = {Brain tumor segmentation using convolutional neural networks in MRI images},
  year      = {2016},
  number    = {5},
  pages     = {1240--1251},
  volume    = {35},
  publisher = {IEEE},
}

@Article{mckinney2020international,
  author    = {McKinney, Scott Mayer and Sieniek, Marcin and Godbole, Varun and Godwin, Jonathan and Antropova, Natasha and Ashrafian, Hutan and Back, Trevor and Chesus, Mary and Corrado, Greg S and Darzi, Ara and others},
  journal   = {Nature},
  title     = {International evaluation of an AI system for breast cancer screening},
  year      = {2020},
  number    = {7788},
  pages     = {89--94},
  volume    = {577},
  publisher = {Nature Publishing Group},
}

@Misc{BibEntry2021Mar,
  month = mar,
  note  = {[Online; accessed 4. May 2022]},
  title = {{Explainable AI}},
  year  = {2021},
  url   = {https://www.ibm.com/watson/explainable-ai},
}

@TechReport{hsieh2022gestaltmatcher,
  author      = {Hsieh, Tzung-Chien and Bar-Haim, Aviram and Moosa, Shahida and Ehmke, Nadja and Gripp, Karen W and Pantel, Jean Tori and Danyel, Magdalena and Mensah, Martin Atta and Horn, Denise and Rosnev, Stanislav and others},
  institution = {Nature Publishing Group},
  title       = {GestaltMatcher facilitates rare disease matching using facial phenotype descriptors},
  year        = {2022},
}

@Misc{gmdb,
  month = may,
  note  = {[Online; accessed 5. May 2022]},
  title = {{GestaltMatcher Database}},
  year  = {2022},
  url   = {https://db.gestaltmatcher.org/publications},
}

@Misc{face2gene,
  month   = mar,
  note    = {[Online; accessed 5. May 2022]},
  title   = {{Home - Face2Gene}},
  year    = {2022},
  journal = {Face2Gene},
  url     = {https://www.face2gene.com},
}

@Article{Gurovich2019,
  author    = {Gurovich, Yaron and Hanani, Yair and Bar, Omri and Nadav, Guy and Fleischer, Nicole and Gelbman, Dekel and Basel-Salmon, Lina and Krawitz, Peter M and Kamphausen, Susanne B and Zenker, Martin and others},
  journal   = {Nature medicine},
  title     = {Identifying facial phenotypes of genetic disorders using deep learning},
  year      = {2019},
  number    = {1},
  pages     = {60--64},
  volume    = {25},
  publisher = {Nature Publishing Group},
}

@Misc{hpo,
	title = {{Human Phenotype Ontology}},
	year = {2022},
	month = apr,
	note = {[Online; accessed 6. May 2022]},
	url = {https://hpo.jax.org/app}
}

@Inproceedings{deng2009imagenet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE conference on computer vision and pattern recognition},
	pages={248--255},
	year={2009},
	organization={Ieee}
}

@Inproceedings{selvaraju2017grad,
	title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
	author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={618--626},
	year={2017}
}

@Article{ghoshal2020estimating,
	title={Estimating uncertainty and interpretability in deep learning for coronavirus (COVID-19) detection},
	author={Ghoshal, Biraja and Tucker, Allan},
	journal={arXiv preprint arXiv:2003.10769},
	year={2020}
}

@Inproceedings{tcav,
	title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
	author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
	booktitle={International conference on machine learning},
	pages={2668--2677},
	year={2018},
	organization={PMLR}
}

@Article{shap,
	title={A unified approach to interpreting model predictions},
	author={Lundberg, Scott M and Lee, Su-In},
	journal={Advances in neural information processing systems},
	volume={30},
	year={2017}
}

@Inproceedings{lime,
	title={" Why should i trust you?" Explaining the predictions of any classifier},
	author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
	pages={1135--1144},
	year={2016}
}

@Article{feature_vis,
	author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
	title = {Feature Visualization},
	journal = {Distill},
	year = {2017},
	note = {https://distill.pub/2017/feature-visualization},
	doi = {10.23915/distill.00007}
}

@Article{guided_backprop,
	title={Striving for simplicity: The all convolutional net},
	author={Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	journal={arXiv preprint arXiv:1412.6806},
	year={2014}
}

@Inproceedings{cam,
	title={Learning deep features for discriminative localization},
	author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={2921--2929},
	year={2016}
}

@Article{ferry_facial_gestalt,
	title={Diagnostically relevant facial gestalt information from ordinary photos},
	author={Ferry, Quentin and Steinberg, Julia and Webber, Caleb and FitzPatrick, David R and Ponting, Chris P and Zisserman, Andrew and Nell{\aa}ker, Christoffer},
	journal={elife},
	volume={3},
	pages={e02020},
	year={2014},
	publisher={eLife Sciences Publications Limited}
}

@Article{attribution_tutorial,
	title={Robust Explainability: A Tutorial on Gradient-Based Attribution Methods for Deep Neural Networks},
	author={Nielsen, Ian E and Dera, Dimah and Rasool, Ghulam and Bouaynaya, Nidhal and Ramachandran, Ravi P},
	journal={arXiv preprint arXiv:2107.11400},
	year={2021}
}

@Article{lrp,
	title={Layer-wise relevance propagation: an overview},
	author={Montavon, Gr{\'e}goire and Binder, Alexander and Lapuschkin, Sebastian and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
	journal={Explainable AI: interpreting, explaining and visualizing deep learning},
	pages={193--209},
	year={2019},
	publisher={Springer}
}

@InProceedings{chen2020adapting,
  author    = {Chen, Lei and Chen, Jianhui and Hajimirsadeghi, Hossein and Mori, Greg},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  title     = {Adapting grad-cam for embedding networks},
  year      = {2020},
  pages     = {2794--2803},
}

@InProceedings{matthew2014visualizing,
  author       = {Matthew Zeiler, D and Rob, Fergus},
  title        = {Visualizing and understanding convolutional neural networks},
  year         = {2014},
  organization = {ECCV},
}

@Misc{kokhlikyan2009unified,
  author = {Kokhlikyan, Narine and Miglani, Vivek and Martin, Miguel and Wang, Edward and Alsallakh, Bilal and Reynolds, Jonathan and Melnikov, Alexander and Kliushkina, Natalia and Araya, Carlos and Yan, Siqi and others},
  title  = {A unified and generic model interpretability library for PyTorch, 2020},
  year   = {2009},
}

@Article{simonyan2013deep,
  author  = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal = {arXiv preprint arXiv:1312.6034},
  title   = {Deep inside convolutional networks: Visualising image classification models and saliency maps},
  year    = {2013},
}

@InProceedings{zeiler2011adaptive,
  author       = {Zeiler, Matthew D and Taylor, Graham W and Fergus, Rob},
  booktitle    = {2011 international conference on computer vision},
  title        = {Adaptive deconvolutional networks for mid and high level feature learning},
  year         = {2011},
  organization = {IEEE},
  pages        = {2018--2025},
}

@Article{krizhevsky2012imagenet,
  author  = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal = {Advances in neural information processing systems},
  title   = {Imagenet classification with deep convolutional neural networks},
  year    = {2012},
  volume  = {25},
}

@Article{ILSVRC15,
  author  = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  journal = {International Journal of Computer Vision (IJCV)},
  title   = {{ImageNet Large Scale Visual Recognition Challenge}},
  year    = {2015},
  number  = {3},
  pages   = {211-252},
  volume  = {115},
  doi     = {10.1007/s11263-015-0816-y},
}

@InProceedings{shrikumar2017learning,
  author       = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle    = {International conference on machine learning},
  title        = {Learning important features through propagating activation differences},
  year         = {2017},
  organization = {PMLR},
  pages        = {3145--3153},
}

@InProceedings{utk_dataset,
  author    = {Zhang, Zhifei and Song, Yang and Qi, Hairong},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  title     = {Age progression/regression by conditional adversarial autoencoder},
  year      = {2017},
  pages     = {5810--5818},
}

@InProceedings{ghorbani2019interpretation,
  author    = {Ghorbani, Amirata and Abid, Abubakar and Zou, James},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  title     = {Interpretation of neural networks is fragile},
  year      = {2019},
  number    = {01},
  pages     = {3681--3688},
  volume    = {33},
}

@Article{10.1145/3236009,
  author     = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
  journal    = {ACM Comput. Surv.},
  title      = {A Survey of Methods for Explaining Black Box Models},
  year       = {2018},
  issn       = {0360-0300},
  month      = {aug},
  number     = {5},
  volume     = {51},
  abstract   = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
  address    = {New York, NY, USA},
  articleno  = {93},
  doi        = {10.1145/3236009},
  issue_date = {September 2019},
  keywords   = {explanations, transparent models, Open the black box, interpretability},
  numpages   = {42},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3236009},
}

@Article{li2017convolutional,
  author  = {Li, Christy and Konomis, Dimitris and Neubig, Graham and Xie, Pengtao and Cheng, Carol and Xing, Eric},
  journal = {arXiv preprint arXiv:1712.02768},
  title   = {Convolutional neural networks for medical diagnosis from admission notes},
  year    = {2017},
}

@Article{9233366,
  author  = {Tjoa, Erico and Guan, Cuntai},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  title   = {A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI},
  year    = {2021},
  number  = {11},
  pages   = {4793-4813},
  volume  = {32},
  doi     = {10.1109/TNNLS.2020.3027314},
}

@Article{miglani2020investigating,
  author  = {Miglani, Vivek and Kokhlikyan, Narine and Alsallakh, Bilal and Martin, Miguel and Reblitz-Richardson, Orion},
  journal = {arXiv preprint arXiv:2010.12697},
  title   = {Investigating saturation effects in integrated gradients},
  year    = {2020},
}

@Article{sheu2020illuminating,
  author    = {Sheu, Yi-han},
  journal   = {Frontiers in Psychiatry},
  title     = {Illuminating the black box: interpreting deep neural network models for psychiatric research},
  year      = {2020},
  pages     = {551299},
  volume    = {11},
  publisher = {Frontiers Media SA},
}

@Article{alvarez2018robustness,
  author  = {Alvarez-Melis, David and Jaakkola, Tommi S},
  journal = {arXiv preprint arXiv:1806.08049},
  title   = {On the robustness of interpretability methods},
  year    = {2018},
}

@Article{smilkov2017smoothgrad,
  author  = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal = {arXiv preprint arXiv:1706.03825},
  title   = {Smoothgrad: removing noise by adding noise},
  year    = {2017},
}

@Article{hooker2018evaluating,
  author = {Hooker, Sara and Erhan, Dumitru and Kindermans, Pieter-Jan and Kim, Been},
  title  = {Evaluating feature importance estimates},
  year   = {2018},
}

@InProceedings{zhou2016learning,
  author    = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  title     = {Learning deep features for discriminative localization},
  year      = {2016},
  pages     = {2921--2929},
}

@Article{shapley_values,
  author    = {{\v{S}}trumbelj, Erik and Kononenko, Igor},
  journal   = {Knowledge and information systems},
  title     = {Explaining prediction models and individual predictions with feature contributions},
  year      = {2014},
  number    = {3},
  pages     = {647--665},
  volume    = {41},
  publisher = {Springer},
}

@Misc{caltech_101,
  author       = {Li and Andreeto and Ranzato and Perona},
  month        = {Apr},
  title        = {Caltech 101},
  year         = {2022},
  abstractnote = {Pictures of objects belonging to 101 categories. About 40 to 800 images per category. Most categories have about 50 images. Collected in September 2003 by Fei-Fei Li, Marco Andreetto, and Marc'Aurelio Ranzato. The size of each image is roughly 300 x 200 pixels. We have carefully clicked outlines of each object in these pictures, these are included under the 'Annotations.tar'. There is also a MATLAB script to view the annotations, 'show_annotations.m'.},
  doi          = {10.22002/D1.20086},
  publisher    = {CaltechDATA},
}

@Misc{caltech_256,
  author       = {Griffin and Holub and Perona},
  month        = {Apr},
  title        = {Caltech 256},
  year         = {2022},
  abstractnote = {We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions.},
  doi          = {10.22002/D1.20087},
  publisher    = {CaltechDATA},
}

@Misc{pascal-voc-2012,
  author       = {Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.},
  howpublished = {http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html},
  title        = {The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults},
}

@Article{ILSVRC15,
  author  = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  journal = {International Journal of Computer Vision (IJCV)},
  title   = {{ImageNet Large Scale Visual Recognition Challenge}},
  year    = {2015},
  number  = {3},
  pages   = {211-252},
  volume  = {115},
  doi     = {10.1007/s11263-015-0816-y},
}

@Article{lecun1998gradient,
  author    = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal   = {Proceedings of the IEEE},
  title     = {Gradient-based learning applied to document recognition},
  year      = {1998},
  number    = {11},
  pages     = {2278--2324},
  volume    = {86},
  publisher = {Ieee},
}
@Article{adebayo2018sanity,
	title={Sanity checks for saliency maps},
	author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
	journal={Advances in neural information processing systems},
	volume={31},
	year={2018}
}
@Article{draelos2020hirescam,
	title={HiResCAM: Faithful location representation in visual attention for explainable 3d medical image classification},
	author={Draelos, Rachel Lea and Carin, Lawrence},
	journal={arXiv preprint arXiv:2011.08891},
	year={2020}
}
@Article{srinivas2019full,
	title={Full-gradient representation for neural network visualization},
	author={Srinivas, Suraj and Fleuret, Fran{\c{c}}ois},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}
@InProceedings{sundararajan2017axiomatic,
	title={Axiomatic attribution for deep networks},
	author={Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	booktitle={International conference on machine learning},
	pages={3319--3328},
	year={2017},
	organization={PMLR}
}
@Article{kokhlikyan2020captum,
	title={Captum: A unified and generic model interpretability library for pytorch},
	author={Kokhlikyan, Narine and Miglani, Vivek and Martin, Miguel and Wang, Edward and Alsallakh, Bilal and Reynolds, Jonathan and Melnikov, Alexander and Kliushkina, Natalia and Araya, Carlos and Yan, Siqi and others},
	journal={arXiv preprint arXiv:2009.07896},
	year={2020}
}
@InProceedings{bau2017network,
	title={Network dissection: Quantifying interpretability of deep visual representations},
	author={Bau, David and Zhou, Bolei and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={6541--6549},
	year={2017}
}
@InProceedings{zhifei2017cvpr,
	title={Age Progression/Regression by Conditional Adversarial Autoencoder},
	author={Zhang, Zhifei, Song, Yang, and Qi, Hairong},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	year={2017},
	organization={IEEE}
}
@Article{boykov2006graph,
	title={Graph cuts and efficient ND image segmentation},
	author={Boykov, Yuri and Funka-Lea, Gareth},
	journal={International journal of computer vision},
	volume={70},
	number={2},
	pages={109--131},
	year={2006},
	publisher={Springer}
}
@article{zhang2018top,
	title={Top-down neural attention by excitation backprop},
	author={Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan},
	journal={International Journal of Computer Vision},
	volume={126},
	number={10},
	pages={1084--1102},
	year={2018},
	publisher={Springer}
}
@article{zhou2014object,
	title={Object detectors emerge in deep scene cnns},
	author={Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	journal={arXiv preprint arXiv:1412.6856},
	year={2014}
}
@article{hoffman2018metrics,
	title={Metrics for explainable AI: Challenges and prospects},
	author={Hoffman, Robert R and Mueller, Shane T and Klein, Gary and Litman, Jordan},
	journal={arXiv preprint arXiv:1812.04608},
	year={2018}
}
@inproceedings{rosenfeld2021better,
	title={Better metrics for evaluating explainable artificial intelligence},
	author={Rosenfeld, Avi},
	booktitle={Proceedings of the 20th international conference on autonomous agents and multiagent systems},
	pages={45--50},
	year={2021}
}
@article{lin2020you,
	title={What do you see? Evaluation of explainable artificial intelligence (XAI) interpretability through neural backdoors},
	author={Lin, Yi-Shan and Lee, Wen-Chuan and Celik, Z Berkay},
	journal={arXiv preprint arXiv:2009.10639},
	year={2020}
}
@article{mohseni2021multidisciplinary,
	title={A multidisciplinary survey and framework for design and evaluation of explainable AI systems},
	author={Mohseni, Sina and Zarei, Niloofar and Ragan, Eric D},
	journal={ACM Transactions on Interactive Intelligent Systems (TiiS)},
	volume={11},
	number={3-4},
	pages={1--45},
	year={2021},
	publisher={ACM New York, NY}
}
@article{yeh2019fidelity,
	title={On the (in) fidelity and sensitivity of explanations},
	author={Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K},
	journal={Advances in Neural Information Processing Systems},
	volume={32},
	year={2019}
}
@inproceedings{kim2018interpretability,
	title={Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)},
	author={Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others},
	booktitle={International conference on machine learning},
	pages={2668--2677},
	year={2018},
	organization={PMLR}
}
@misc{likert_scale,
	author = "{Wikipedia contributors}",
	title = "Likert scale --- {Wikipedia}{,} The Free Encyclopedia",
	year = "2022",
	url = "https://en.wikipedia.org/w/index.php?title=Likert_scale&oldid=1109849563",
	note = "[Online; accessed 6-November-2022]"
}
@inproceedings{deng2020retinaface,
	title={Retinaface: Single-shot multi-level face localisation in the wild},
	author={Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={5203--5212},
	year={2020}
}
@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}
@article{paszke2019pytorch,
	title={Pytorch: An imperative style, high-performance deep learning library},
	author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}
@misc{jacobgilpytorchcam,
	title={PyTorch library for CAM methods},
	author={Jacob Gildenblat and contributors},
	year={2021},
	publisher={GitHub},
	howpublished={\url{https://github.com/jacobgil/pytorch-grad-cam}},
}
@article{yi2014learning,
	title={Learning face representation from scratch},
	author={Yi, Dong and Lei, Zhen and Liao, Shengcai and Li, Stan Z},
	journal={arXiv preprint arXiv:1411.7923},
	year={2014}
}
@inproceedings{muhammad2020eigen,
	title={Eigen-cam: Class activation map using principal components},
	author={Muhammad, Mohammed Bany and Yeasin, Mohammed},
	booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
	pages={1--7},
	year={2020},
	organization={IEEE}
}
@book{bovik2009essential,
	title={The essential guide to image processing},
	author={Bovik, Alan C},
	year={2009},
	publisher={Academic Press}
}
@book{hartley2003multiple,
	title={Multiple view geometry in computer vision},
	author={Hartley, Richard and Zisserman, Andrew},
	year={2003},
	publisher={Cambridge university press}
}
@misc{cmu_triangle:_nodate,
	title = {Triangle: {Definitions}},
	url = {https://www.cs.cmu.edu/~quake/triangle.defs.html},
	urldate = {2022-11-13},
}
@article{simonyan2014very,
	title={Very deep convolutional networks for large-scale image recognition},
	author={Simonyan, Karen and Zisserman, Andrew},
	journal={arXiv preprint arXiv:1409.1556},
	year={2014}
}
@article{vilone2021notions,
	title={Notions of explainability and evaluation approaches for explainable artificial intelligence},
	author={Vilone, Giulia and Longo, Luca},
	journal={Information Fusion},
	volume={76},
	pages={89--106},
	year={2021},
	publisher={Elsevier}
}
@article{kline2018diagnosis,
	title={Diagnosis and management of Cornelia de Lange syndrome: first international consensus statement},
	author={Kline, Antonie D and Moss, Joanna F and Selicorni, Angelo and Bisgaard, Anne-Marie and Deardorff, Matthew A and Gillett, Peter M and Ishman, Stacey L and Kerr, Lynne M and Levin, Alex V and Mulder, Paul A and others},
	journal={Nature Reviews Genetics},
	volume={19},
	number={10},
	pages={649--666},
	year={2018},
	publisher={Nature Publishing Group}
}
@article{brand2022next,
	title={Next-generation phenotyping contributing to the identification of a 4.7 kb deletion in KANSL1 causing Koolen-de Vries syndrome},
	author={Brand, Fabian and Vijayananth, Aswinkumar and Hsieh, Tzung-Chien and Schmidt, Axel and Peters, Sophia and Mangold, Elisabeth and Cremer, Kirsten and Bender, Tim and Sivalingam, Sugirthan and Hundertmark, Hela and others},
	journal={Human Mutation},
	volume={43},
	number={11},
	pages={1659--1665},
	year={2022},
	publisher={Wiley Online Library}
}
@inproceedings{taigman2014deepface,
	title={Deepface: Closing the gap to human-level performance in face verification},
	author={Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={1701--1708},
	year={2014}
}
@misc{wiki_clin_gen,
	author = "{Wikipedia contributors}",
	title = "Medical genetics --- {Wikipedia}{,} The Free Encyclopedia",
	year = "2022",
	howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Medical_genetics&oldid=1097691695}",
	note = "[Online; accessed 28-November-2022]"
}
@misc{wiki_pheno,
	author = "{Wikipedia contributors}",
	title = "Phenotype --- {Wikipedia}{,} The Free Encyclopedia",
	year = "2022",
	howpublished = "\url{https://en.wikipedia.org/w/index.php?title=Phenotype&oldid=1105591772}",
	note = "[Online; accessed 28-November-2022]"
}
@article{eig_faces,
	author={Kirby, M. and Sirovich, L.},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Application of the Karhunen-Loeve procedure for the characterization of human faces}, 
	year={1990},
	volume={12},
	number={1},
	pages={103-108},
	doi={10.1109/34.41390}}
@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Markings\;2\;1\;\;\;\;;
2 StaticGroup:[ash:]\;2\;1\;\;\;\;;
2 StaticGroup:ash:6\;2\;1\;\;\;\;;
}
