%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}
\begin{document}
    \chapter{Introduction}\label{ch_intro}
    \noindent
	 \enquote {Artificial neural networks (ANNs) are increasingly applied for medical image diagnostics} \cite{anwar2018medical}. Medical image data such as scans produced from imaging devices like x-rays \cite{ozturk2020automated}, magnetic resonance imaging (MRI) \cite{xue2012window}, computed tomography (CT) \cite{lee2019explainable}, and ultrasound \cite{qian2021prospective}, waveforms produced from procedures like electrocardiography (ECG) \cite{hicks2021explaining} and electroencephalography (EEG), histological images \cite{binder2021morphological}, images of body parts, and admission notes \cite{li2017convolutional} are fed into ANNs to perform tasks such as segmentation \cite{Schwendicke2019}, classification \cite{Gurovich2019} and abnormality detection \cite{binder2021morphological}.
	
	Predictions made by neural network models are typically intended to be used in a clinical setting to aid medical practitioners in diagnosing their patients. As a result, it can help in an overall reduction of \enquote{misdiagnosis}, which is one of the most severe problems in health care \cite{li2017convolutional}. Besides, the adoption of ANN based artificial intelligence (AI) systems facilitate early screening and identification of life-threatening conditions such as cancer in a population with limited or no access to sub-specialty trained clinicians.
	
	ANN models such as the ones used in AI systems for intracranial haemorrhage classification \cite{lee2019explainable} and breast cancer prediction  \cite{mckinney2020international} outperform clinicians in their respective tasks. However, in spite of their success in terms of predictive performance, the black-box nature of ANNs restrains them from getting deployed in a clinical setting. Inherently, ANNs lack transparency and therefore are considered less dependable for high stake applications like medical diagnosis and autonomous driving. Besides, regulatory bodies such as \enquote{US FDA (United States Food and Drug Administration) require any clinical decision support software to explain the rationale or support for its decisions to enable the users to independently review the basis of their recommendations} \cite{lee2019explainable}. Such contradictions further restrict the deployment of ANN-based AI systems for performing medical diagnoses in a clinical setting.
	
	\enquote{Explainable artificial intelligence (XAI) is a set of processes and methods that allows human users to comprehend and trust the results and output created by machine learning algorithms} \cite{BibEntry2021Mar}. Application of XAI techniques to machine learning (ML) models enables its human users to better understand their behavior and the rationale behind their predictions. As a result, they improve the transparency of models like ANNs, in turn making them more trustworthy for applications like medical diagnosis.
	
	Recently, there has been a steep rise in the adoption of XAI methods to explain ANN models for medical diagnoses. A considerable number of existing works focus on explaining neural network models that use radiological image data to perform tasks such as COVID classification \cite{ghoshal2020estimating}, breast cancer risk assessment \cite{qian2021prospective}, and haemorrhage detection \cite{lee2019explainable} respectively. A few others leverage XAI techniques to explain neural network models used for detecting cancer from histopathological \cite{binder2021morphological} and skin images \cite{nunnari2021overlap}. 
	
	This thesis aims to use XAI to explain one such neural network model called GestaltMatcher \cite{hsieh2022gestaltmatcher}, which surpasses the performance of clinical practitioners in the identification of certain rare genetic syndromes, from frontal facial images of patients. Further more, the findings of this work shall make the GestaltMatcher model more transparent and dependable, thereby taking it a step closer to be deployed in a clinical setting.
	
	%The objective of this thesis is to apply suitable XAI techniques to one such state-of-the-art (SOTA) genetic syndrome recognition model called GestaltMatcher \cite{hsieh2022gestaltmatcher}, whose performance surpasses that of clinicians. with intents to make the models explainable and to determine their attention regions in a given facial image. The following subsections describe the motivation behind pursuing this work and lists the relevant research questions that are addressed by this thesis.% 
	

    \section{Motivation}
    \noindent
    \enquote{Rare genetic disorders affect more than 6.2\% of the global population} \cite{hsieh2022gestaltmatcher}. A significant fraction of the population with certain such disorders is characterized by facial abnormalities, which make up their respective facial phenotypes\footnote{\enquote{Phenotype is the set of observable characteristics or traits of an organism}\cite{wiki_pheno}}. The facial phenotypic information is used by clinical geneticists along with results from other laboratory tests, such as molecular, to reach a diagnosis. However, the rarity in the occurrence of such disorders, combined with the lack of distinctive traits for a subset of them, makes their diagnosis a challenging task even for experienced medical practitioners.  
    
    ANN models such as the ones presented in DeepGestalt \cite{Gurovich2019} and GestaltMatcher comprise a promising step forward in using AI for the task of recognizing rare genetic disorders from facial phenotypes. Such works rely on databases like Face2Gene \cite{face2gene} and GestaltMatcher database (GMDB) \cite{gmdb}  which offer a valuable collection of frontal facial images and other medical data of the patients with such rare disorders. The GestaltMatcher model surpasses human experts' performance in the task of recognizing certain syndromes and their subtypes. Therefore, the deployment of such models in a clinical setting has the potential to significantly improve the speed and accuracy of diagnoses.
    
    The constraints on deploying ANN models for medical diagnoses in a clinical setting, as discussed in the previous section, apply to the genetic disorder classifiers as well. Therefore, there is an obligation for such models to provide bases for their predictions in order to make them dependable. However, none of the existing works on genetic disorder classification from frontal facial images focus on the explainability of their models.
    
    In general, ANN models are capable of learning novel discriminative features or regions from the training data that are relevant to the task at hand. Associating such learned features or regions with real world knowledge (with respect to the dataset) can provide new insights about the data and task at hand. In the case of genetic disorder classification, associating attention regions of state-of-the-art (SOTA) models like DeepGestalt \cite{Gurovich2019} and GestaltMatcher in their frontal facial input images, can enhance humankind's understanding of facial phenotypes of genetic disorders. Such a study to associate the attention regions of genetic disorder classifiers with the facial phenotypic information known to the medical community is yet to be conducted.
    
    \section{Importance} \label{sec_importance}
    \noindent
    Making a genetic disorder classifier explainable by determining its attention regions offers a means for its users to check whether the model focuses on features relevant to a given disorder, or something irrelevant, like background, for example. In the former case, a clinician could use the model's prediction to reinforce his diagnosis. In the latter, they could simply ignore its decisions. Thus an explainable genetic disorder classifier provides a verifiable second opinion to a clinical geneticist\footnote{\enquote{A clinical geneticist is typically a physician who evaluates patients in the office or as a hospital consultation. This process includes a medical history, family history, a detailed physical examination, reviewing objective data such as imaging and test results, establishing a differential diagnosis, and recommending appropriate diagnostic tests.} \cite{wiki_clin_gen}}.
    
    The knowledge about facial phenotypes of rare genetic disorders are contained in resources like Human Phenotype Ontology (HPO) \cite{hpo} and relevant medical literature. However, due to rare occurrences of such disorders, not all variations in their phenotypes are known to the medical community. Analyzing the attention regions of genetic disorder classifier models offers a way to discover facial regions that contain novel phenotypic traits, thereby enhancing humankind's understanding of such rare medical conditions.
    
    Datasets like GMDB only contain a fractional number of instances per class when compared with sizes of general-purpose image classification datasets like ImageNet \cite{deng2009imagenet}. Most of the disorder classes contain samples in the order of tens and a few in the order of hundreds. This, inturn,  demands use of highly effective data pre-processing and model training techniques to learn the most from a dataset. Analyzing attention regions of a classifier model trained on such datasets enables an ML practitioner to identify any possible biases that the model could have learned and consecutively enables him to adopt suitable techniques to remove them. This eventually makes the model more generalized and possibly increases its predictive performance. 
    
    \section{Challenges and Difficulties} \label{sec_challenges}
    This section lists and discusses some of the key challenges associated with this research work.
	\begin{itemize}
		\item \textbf{Dataset size and imbalance: }As briefly mentioned in the previous section, datasets like GMDB are small-sized and also are characterized by problems such as dataset imbalance and low image resolution. Such problems are caused by various factors like an inherent rarity in the occurrence of genetic syndromes, data-privacy constraints, and lack of openly available datasets. The above-listed issues of genetic syndrome datasets often have consequential effects on the performance and explainability of the machine learning models with which they are trained. 

		\item \textbf{Low predictive performance of the classifier: }Although SOTA genetic syndrome classifier models such as DeepGestalt and GestaltMatcher surpass human-level performance in diagnosing rare genetic disorders, their predictive performances are exceptionally low when compared with that of top classification models trained on large general purpose datasets. Besides, over-fitting is a common problem experienced by these models. In most of the existing works on XAI methods for neural networks, the research community has benchmarked them on high-performance models. This raises doubts about the quality of explanations generated by XAI methods when applied to low-performance models.
	
		\item \textbf{Lack of ground truth explanations: }Evaluating the performance and effectiveness of XAI methods remains a challenge to date. In most cases, this is due to the lack of any ground truth and/or metrics to evaluate their explanations. Besides, the working principle of every XAI method is different, with each focusing on explaining a particular aspect of the model and its predictions. Due to this reason, often, XAI methods are evaluated by subjecting their corresponding artifacts to be assessed by humans. In the case of this work, such an evaluation needs to be performed by clinicians and dysmorphologists who specialize in the diagnosis of rare genetic syndromes. Certain practical difficulties in conducting such an evaluation, like the willingness of clinicians to participate in the process, pose a challenge. In addition, new findings and discoveries about phenotypic features and new variants of genetic syndromes change the medical community's understanding of them from time to time, questioning the correctness of clinical evaluation conducted at a given point in time.
\end{itemize}
   
    \section{Problem Statement}
    \noindent
 	This research work systematically approaches the problem at hand. Firstly, a literature review is conducted to identify SOTA XAI methods, which, when applied to the GestaltMatcher model, explains the rationale behind its predictions in the form of post-hoc attention maps. In a classification setup, post-hoc attention heat maps signal regions in the input image that were relevant for a classifier model to produce a certain class label. A handful of XAI methods are shortlisted based on their advantages and drawbacks, recommendations from the research community, and their suitability to the task at hand. 
 	
 	The selected set of techniques is applied to GestaltMatcher in order to generate explanations associated with the model's predictions for every patient image in the GMDB dataset. The generated explanations are then analyzed with the intents of understanding the behaviours of both the model and the chosen set of XAI techniques with different input categories. Besides analyzing the model's regions of interest in individual patient images, this work also studies its characteristic attention regions on a class level for specific syndromes. Such characteristic representations are produced by combining patient-wise attention maps of individual classes. 
 	
 	As mentioned in \ref{sec_challenges}, dataset imbalance is one of the key challenges in the application of ML techniques to medical data. This can have consequences on the quality of attention maps generated for classes of different sizes. This work conducts experiments to analyze the effects of class imbalance on the quality of explanation artifacts. This is achieved by comparing attention maps produced from classifier models that are trained with different numbers and choices for the syndrome classes. 
 	
 	In order to know the association between GestaltMatcher's attention regions and the medical community's knowledge of facial phenotypic features of genetic syndromes, the model's attention maps are evaluated by an experienced clinical geneticist. An evaluation procedure is formulated and realized in the form of a questionnaire, which is then filled out by the clinician. A detailed analysis of his responses is performed with the intents of comparing the chosen set of XAI methods based on the usefulness of attribution maps generated by them, and getting new insights into data and working of the neural network model.
 	 
 	\subsubsection{Research Questions} \label{sec_rq}
 	Concisely put, this thesis intends to address the following research questions:% 
 	\begin{enumerate}
 		\item [] \textbf{RQ1.} What are the XAI methods to determine important regions in an input image for a CNN-based classifier model to make its predictions?  
 		\item [] \textbf{RQ2.} What are the key regions in frontal facial images fed to CNN models trained for the task of classifying rare genetic disorders?
 		\item [] \textbf{RQ3.} How do the regions obtained from findings for RQ2 compare with the knowledge known to the medical community on facial phenotypes of the corresponding rare genetic disorders? 
 	\end{enumerate}
 
 	\section{Structure}
 	\noindent
 	This report consists of seven chapters (including this chapter), with each discussing different aspects of the conducted research work. The first chapter introduced the reader to the research topic and discussed the scope and significance of this work. Chapter 2 gives the necessary background knowledge on the diagnosis of rare genetic conditions using GestaltMatcher \cite{hsieh2022gestaltmatcher}, which is necessary to appreciate this work. The chapter also briefly introduces the reader to the field of XAI. In Chapter 3, a literature review of SOTA explanation methods considered for this research work is provided. Chapter 4 describes the systematic approach taken to address the problem at hand. The chapter gives the rationale behind the design of experiments and other choices made. The fifth chapter discusses the implementation details of experiments and presents the questionnaire to the reader. Results of the conducted experiments and the clinician's evaluation are presented and analyzed in Chapter 6. Finally, Chapter 7 concludes the report by giving a summary of this project's contributions and also provides a few possible future research directions. 
 	
 	
\end{document}
